{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2\n",
    "\n",
    "- Preparação e pre-processamento dos dados para a aplicação nos modelos.\n",
    "- Geração de ambiente de testes básico para os modelos\n",
    "- Filtragem de modelos viáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 1\n",
    "\n",
    "Substituir colunas \"open\" e \"close\" pela media e diferenca delas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma pergunta que deve ser feita é. Como lidar com o fato de existirem tantas empresas. Será que os dados delas devem ser todos agregados em um só conjunto para a Bolsa? Ou será que é possível tratá-los do jeito que estão?\n",
    "\n",
    "Um jeito melhor de formular essa pergunta é o seguinte. Será que o símbolo da empresas (atributo categórico) deve ser um dos parâmetros do modelo?\n",
    "\n",
    "Para avaliar uma resposta, podemos colocar alguns fatores em jogo.\n",
    "\n",
    "- Complexidade: qual seria mais difícil de construir, o agregado ou o sem agregação?\n",
    "- Utilidade (em vista do objetivo de negócio): Note que o objetivo de negócio menciona, e com razão, \"robustez\". É bem claro que um preditor que leve em conta especificamente a qual empresa se refere, terá melhores resultados que um preditor que agrega tudo (perdendo tantos graus de liberdade). Além disso, como demonstrado na fase 1 pela comparação entre as empresas IBM e Fox, cada uma tem suas peculiaridades. Analisá-las em conjunto pode trazer um grande prejuízo para a acurácia do modelo.\n",
    "\n",
    "Essa discussão levanta um ponto interessante. O banco de dados original consiste não somente no arquivo \"prices.csv\" que estamos utilizando, mas também de outros arquivos, por exemplo tabelas que trazem informações cruciais sobre a empresa. Esse ponto é interessante porque, das desvantagens de se tomar o símbolo da empresa como parâmetro para o modelo, se destaca a incapacidade de generalizar para novas empresas que surgirem, ou para mudanças de nome (mudanças do símbolo da empresa teriam que ser tratadas manualmente). Seria interessante se as empresas pudessem ser classificadas por setor (e.g. IT, media, etc), por exemplo, como um passo de pre-processamento de entradas para o modelo.\n",
    "\n",
    "OK. Acho que o que precisamos fazer é codificar essas variáveis categóricas com o que se pode encontrar no arquivo \"fundamentals.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One question that I would like to raise here is,\n",
    "is our model really going to need this transformation?**\n",
    "\n",
    "We have decided to leave the consideration of low & high to after the model testing framework is built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 2\n",
    "\n",
    "> Compilar uma lista de modelos compatı́veis com as observações feitas até o\n",
    "momento. Comparar analiticamente estes modelos, deixando na lista somente modelos\n",
    "que se confundirem em termos de qualidade esperada. Esta classificação deve seguir\n",
    "conhecimentos de mineração de dados e experiências passadas, tanto do autor como de\n",
    "grupos externos, com o problema em questão.\n",
    "\n",
    "Esses \"modelos compatíveis\" querem dizer modelos que parecerem produtivos para atingir os objetivos de negócio (notavelmente de regressão, para a tarefa que temos em mãos). Lembrando o objetivo de negócio:\n",
    "\n",
    "> Produzir um preditor robusto para o preço de ações na bolsa de\n",
    "Nova York."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quais modelos de regressao devem ser considerados?\n",
    "\n",
    "- Linear regression\n",
    "- Logistic regression\n",
    "- Neural networks\n",
    "- Decision tree / random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre cada modelo, quais são qualidade procuradas?\n",
    "\n",
    "- Automated (no need to search for heuristics for augmentation) --- neural networks shine here\n",
    "- Adaptation to the NYSE data --- no idea\n",
    "- Interpretability (decision trees may be best here)\n",
    "- Computational speed, Memory usage(dataset is pretty big) --- linear regression may be best here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quais modelos podem ser desconsiderados\n",
    "\n",
    "- Logistic regression (até onde eu sei é usado mais para classificação)\n",
    "- Neural networks (é mais complexa que o necessário)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about regularization?\n",
    "\n",
    "- Have to decide on the parameters (for example for ridge regression, the norm of the weights is used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, there needs to be thought on data normalization\n",
    "\n",
    "- Gaussian normalization.\n",
    "- Attribute weights to each feature. I think they should be different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3\n",
    "\n",
    "Criar um ambiente de testes para os modelos escolhidos.\n",
    "\n",
    "Entre regressão linear e árvores de decisão, decidir ir com regressão linear mesmo. Tem mais chances de se dar bem com o modelo. Penso que a kernelização não será um problema (posso utilizar kernel polinomial misto até grau 3).\n",
    "\n",
    "A tarefa se torna então criar um ambiente (código Python) para a testagem do modelo com z-normalização.\n",
    "\n",
    "Note que não é necessário aplicar o modelo aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/frame.py:4110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Todo o processo mencionado acima é feito nessa função\n",
    "filtPricesDf = fetchFiltPricesDf(pricesDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coisa que apareceu aqui é que não parece razoável simplesmente criar um modelo de regressão sobre os dados normalizados dessa forma. Há uma cauda muito pesada para a direita nas curvas gaussianas.\n",
    "\n",
    "Estou pensando em resolver isso através de uma etapa prévia de agrupamento na etapa de treinamento e também na etapa de testes. Isto é, primeiro se distingue a qual grupo o ponto pertence, e depois se passa o resultado para o modelo de regressão em si.\n",
    "\n",
    "Penso que não será muito complicado fazer isso.\n",
    "\n",
    "Em primeiro lugar, porém, vale a pena testar o modelo como está."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to divide the dataset into three parts: training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = splitTrainTest(filtPricesDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this notebook. The rest will be put in the next phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
